{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "xoV24v5xHJ95",
    "tags": []
   },
   "source": [
    "# Ateema Capstone Project\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "_l46A-aYHJ97"
   },
   "source": [
    "## Local models\n",
    "\n",
    "#### Embedding\n",
    "\n",
    "[GPT4All Embeddings](https://blog.nomic.ai/posts/nomic-embed-text-v1):\n",
    "\n",
    "```\n",
    "pip install langchain-nomic\n",
    "```\n",
    "\n",
    "### LLM\n",
    "\n",
    "Use [Ollama](https://ollama.ai/) and [llama3](https://ollama.ai/library/llama3):\n",
    "\n",
    "```\n",
    "ollama pull llama3\n",
    "```\n",
    "\n",
    "Prompt -\n",
    "\n",
    "https://llama.meta.com/docs/model-cards-and-prompt-formats/meta-llama-3/\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "qG_0zcNDHJ97",
    "tags": []
   },
   "source": [
    "## Libraries"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 78,
   "metadata": {
    "id": "DdZ6r1paJElM"
   },
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import os\n",
    "\n",
    "from langchain.chains import RetrievalQA\n",
    "from langchain.document_loaders import TextLoader\n",
    "from langchain_community.embeddings import GPT4AllEmbeddings\n",
    "from langchain.text_splitter import RecursiveCharacterTextSplitter\n",
    "from langchain.vectorstores import Chroma\n",
    "from langchain.document_loaders.csv_loader import CSVLoader\n",
    "from langchain_community.chat_models import ChatOllama\n",
    "from langchain_core.output_parsers import StrOutputParser\n",
    "from langchain.prompts import PromptTemplate\n",
    "from langchain_core.prompts import ChatPromptTemplate\n",
    "from langchain_core.output_parsers import JsonOutputParser\n",
    "from langchain.schema import Document\n",
    "from langgraph.graph import END, StateGraph\n",
    "\n",
    "from typing_extensions import TypedDict\n",
    "from typing import List\n",
    "from pprint import pprint\n",
    "\n",
    "# LLM\n",
    "local_llm = 'llama3'"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "TY9lMrr8HJ98",
    "tags": []
   },
   "source": [
    "## Setup"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 74,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "N30R7yBwIgpR",
    "outputId": "52fb8f93-50d7-411e-b671-77da4a5b5f8e"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Drive already mounted at /content/drive; to attempt to forcibly remount, call drive.mount(\"/content/drive\", force_remount=True).\n"
     ]
    }
   ],
   "source": [
    "from google.colab import drive\n",
    "drive.mount('/content/drive')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 75,
   "metadata": {
    "id": "CY7NJYTMIk9o"
   },
   "outputs": [],
   "source": [
    "# data loader\n",
    "loader = CSVLoader(file_path=\"/content/drive/MyDrive/stage1_all.csv\")\n",
    "data = loader.load()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 91,
   "metadata": {
    "id": "i1zo4aMVHJ99"
   },
   "outputs": [],
   "source": [
    "from gpt4all import Embed4All\n",
    "from langchain.text_splitter import RecursiveCharacterTextSplitter\n",
    "from langchain.vectorstores import Chroma\n",
    "from langchain_community.chat_models import ChatOllama\n",
    "from langchain.prompts import PromptTemplate\n",
    "from langchain_core.output_parsers import JsonOutputParser\n",
    "\n",
    "# Assume `data` is already loaded\n",
    "\n",
    "# Data transformers\n",
    "text_splitter = RecursiveCharacterTextSplitter.from_tiktoken_encoder(\n",
    "    chunk_size=250, chunk_overlap=0\n",
    ")\n",
    "texts = text_splitter.split_documents(data)\n",
    "\n",
    "# Initialize embeddings\n",
    "embedder = Embed4All()\n",
    "\n",
    "# Generate embeddings for documents\n",
    "embeddings = [embedder.embed(doc.page_content) for doc in texts]\n",
    "\n",
    "# Create a dictionary to map document content to their embeddings\n",
    "embedding_dict = {doc.page_content: embedding for doc, embedding in zip(texts, embeddings)}\n",
    "\n",
    "# Define a custom embedding function\n",
    "class CustomEmbeddingFunction:\n",
    "    def __init__(self, embedder, embedding_dict):\n",
    "        self.embedder = embedder\n",
    "        self.embedding_dict = embedding_dict\n",
    "\n",
    "    def embed_documents(self, texts):\n",
    "        return [self.embedding_dict[text] for text in texts]\n",
    "\n",
    "    def embed_query(self, text):\n",
    "        return self.embedder.embed(text)\n",
    "\n",
    "# Initialize the custom embedding function\n",
    "custom_embedding = CustomEmbeddingFunction(embedder, embedding_dict)\n",
    "\n",
    "# Add to vectorDB\n",
    "vectorstore = Chroma.from_documents(\n",
    "    documents=texts,\n",
    "    embedding=custom_embedding,\n",
    "    collection_name=\"rag-chroma\"\n",
    ")\n",
    "\n",
    "# Retriever\n",
    "retriever = vectorstore.as_retriever()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "g1wcqouyHJ99",
    "tags": []
   },
   "source": [
    "## Retrieval Grader\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 92,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "Q2H8NfZoHJ99",
    "outputId": "ed2316d1-47cf-4213-f78c-ac1413f08513"
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/usr/local/lib/python3.10/dist-packages/langchain_core/_api/deprecation.py:119: LangChainDeprecationWarning: The method `BaseRetriever.get_relevant_documents` was deprecated in langchain-core 0.1.46 and will be removed in 0.3.0. Use invoke instead.\n",
      "  warn_deprecated(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'score': 'yes'}\n"
     ]
    }
   ],
   "source": [
    "# LLM\n",
    "llm = ChatOllama(model=\"llama3\", format=\"json\", temperature=0)\n",
    "\n",
    "# Define prompt\n",
    "prompt = PromptTemplate(\n",
    "    template=\"\"\"system You are a grader assessing relevance\n",
    "    of a retrieved document to a user question. If the document contains keywords related to the user question,\n",
    "    grade it as relevant. It does not need to be a stringent test. The goal is to filter out erroneous retrievals. \\n\n",
    "    Give a binary score 'yes' or 'no' score to indicate whether the document is relevant to the question. \\n\n",
    "    Provide the binary score as a JSON with a single key 'score' and no premable or explaination.\n",
    "     user\n",
    "    Here is the retrieved document: \\n\\n {document} \\n\\n\n",
    "    Here is the user question: {question} \\n assistant\n",
    "    \"\"\",\n",
    "    input_variables=[\"question\", \"document\"],\n",
    ")\n",
    "\n",
    "retrieval_grader = prompt | llm | JsonOutputParser()\n",
    "\n",
    "# Example question\n",
    "question = \"My name is Sanjay. I will be visiting Chicago in summer with my family to explore and would like to go to interesting places.\"\n",
    "\n",
    "# Retrieve documents\n",
    "docs = retriever.get_relevant_documents(question)\n",
    "doc_txt = docs[0].page_content\n",
    "\n",
    "# Grade the relevance\n",
    "result = retrieval_grader.invoke({\"question\": question, \"document\": doc_txt})\n",
    "print(result)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "PP6bqJx7HJ9-",
    "tags": []
   },
   "source": [
    "## Generation\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 93,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "OQ5MuSBfHJ9-",
    "outputId": "fb924c74-4cf1-4bd5-9d3c-9f57cb981110"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Sanjay! Welcome to Chicago in the summer! I'm Ateema, your AI tour guide. I've got some fantastic recommendations for you and your family to enjoy the city's beautiful beaches and more.\n",
      "\n",
      "As you're looking for interesting places to visit, I'll give you my top 10 picks, ranked from 1 to 10. Here they are:\n",
      "\n",
      "**Rank 1: North Avenue Beach**\n",
      "Start your beach-hopping adventure at North Avenue Beach, one of Chicago's most popular spots. Enjoy the sun, sand, and stunning views of Lake Michigan. You can even take a dip in the lake or try your hand at surfing!\n",
      "\n",
      "**Rank 2: Oak Street Beach**\n",
      "Next up is Oak Street Beach, a hidden gem with plenty of room to spread out and soak up the sun. Take a stroll along the beachfront path, grab a snack from one of the many food vendors, and enjoy the lively atmosphere.\n",
      "\n",
      "**Rank 3: Montrose Beach**\n",
      "Montrose Beach is another must-visit spot for beach lovers. With its picturesque views and calm waters, it's perfect for families or those looking to relax. Don't miss the nearby Montrose Dog Beach, where your furry friends can run free!\n",
      "\n",
      "**Rank 4: Belmont Harbor Beach**\n",
      "Belmont Harbor Beach offers a unique experience with its scenic harbor views and tranquil atmosphere. Take a leisurely walk along the beachfront path, grab a bite to eat at one of the many restaurants, or simply sit back and enjoy the sunset.\n",
      "\n",
      "**Rank 5: Foster Beach**\n",
      "Foster Beach is a local favorite, known for its soft sand and calm waters. It's an excellent spot for swimming, sunbathing, or trying your hand at beach volleyball. Don't miss the nearby Foster Avenue Beach House, offering food, drinks, and beach gear rentals.\n",
      "\n",
      "**Rank 6: Hollywood Beach**\n",
      "Hollywood Beach is a family-friendly destination with plenty of room to play and relax. Enjoy the playground, splash pad, and picnic areas while taking in the beautiful views of Lake Michigan.\n",
      "\n",
      "**Rank 7: Rainbow Beach**\n",
      "Rainbow Beach is a vibrant spot with a colorful beachfront path and plenty of activities for all ages. Take a stroll along the lakefront trail, grab a snack from one of the many food vendors, or simply enjoy the lively atmosphere.\n",
      "\n",
      "**Rank 8: Ohio Street Beach**\n",
      "Ohio Street Beach is another popular spot with its wide stretch of sand and calm waters. Enjoy swimming, sunbathing, or trying your hand at beach games like volleyball or frisbee.\n",
      "\n",
      "**Rank 9: 57th Street Beach**\n",
      "57th Street Beach is a hidden gem with plenty of room to spread out and enjoy the views. Take a stroll along the lakefront path, grab a snack from one of the many food vendors, or simply sit back and relax.\n",
      "\n",
      "**Rank 10: 31st Street Beach**\n",
      "Last but not least, we have 31st Street Beach, a quiet spot perfect for those looking to unwind. Enjoy the peaceful atmosphere, take a stroll along the lakefront path, or simply sit back and soak up the sun.\n",
      "\n",
      "And that's it, Sanjay! These are my top 10 picks for Chicago's beautiful beaches. Whether you're looking for adventure, relaxation, or family fun, there's something for everyone in this amazing city. Enjoy your summer in Chicago!\n",
      "\n",
      "(End of prompt)\n"
     ]
    }
   ],
   "source": [
    "# # Prompt\n",
    "# prompt = PromptTemplate(\n",
    "#     template=\"\"\"<|begin_of_text|><|start_header_id|>system<|end_header_id|> You are an assistant for question-answering tasks.\n",
    "#     Use the following pieces of retrieved context to answer the question. If you don't know the answer, just say that you don't know.\n",
    "#     Use three sentences maximum and keep the answer concise <|eot_id|><|start_header_id|>user<|end_header_id|>\n",
    "#     Question: {question}\n",
    "#     Context: {context}\n",
    "#     Answer: <|eot_id|><|start_header_id|>assistant<|end_header_id|>\"\"\",\n",
    "#     input_variables=[\"question\", \"document\"],\n",
    "# )\n",
    "\n",
    "prompt = PromptTemplate(\n",
    "    template=\"\"\"<|begin_of_text|><|start_header_id|>system<|end_header_id|> You are an AI tour guide named Ateema. Your role is to assist users in finding interesting places to visit.\n",
    "    Greet the user warmly and provide recommendations based on their specified location. Provide a detailed description of each place ranked up to 10 places and why it might be interesting to the user.\n",
    "    The prompt length targets up to 60 seconds that explicitly states what I asked you to and end a prompt like a professional tour guide as there will be no continuging conversation after generating a prompt. <|eot_id|><|start_header_id|>user<|end_header_id|>\n",
    "    Question: {question}\n",
    "    Context: {context}\n",
    "    Answer: <|eot_id|><|start_header_id|>assistant<|end_header_id|>\"\"\",\n",
    "    input_variables=[\"question\", \"document\"],\n",
    ")\n",
    "\n",
    "llm = ChatOllama(model=local_llm, temperature=0)\n",
    "\n",
    "# Post-processing\n",
    "def format_docs(docs):\n",
    "    return \"\\n\\n\".join(doc.page_content for doc in docs)\n",
    "\n",
    "# Chain\n",
    "rag_chain = prompt | llm | StrOutputParser()\n",
    "\n",
    "\n",
    "# Run\n",
    "question = \"My name is Sanjay. I will be visiting Chicago in summer with my family to explore and would like to go to interesting places.\"\n",
    "\n",
    "# Understanding retriever relevant metrics\n",
    "docs = retriever.invoke(question)\n",
    "generation = rag_chain.invoke({\"context\": docs, \"question\": question})\n",
    "print(generation)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "GY7xuOGYHJ9_",
    "tags": []
   },
   "source": [
    "## Hallucination Grader\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 94,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "Tweppl4PHJ9_",
    "outputId": "aee7a03e-be83-4ab1-c80e-7dd3c94ca937"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'score': 'yes'}"
      ]
     },
     "execution_count": 94,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# LLM\n",
    "llm = ChatOllama(model=local_llm, format=\"json\", temperature=0)\n",
    "\n",
    "# Prompt\n",
    "prompt = PromptTemplate(\n",
    "    template=\"\"\" <|begin_of_text|><|start_header_id|>system<|end_header_id|> You are a grader assessing whether\n",
    "    an answer is grounded in / supported by a set of facts. Give a binary 'yes' or 'no' score to indicate\n",
    "    whether the answer is grounded in / supported by a set of facts. Provide the binary score as a JSON with a\n",
    "    single key 'score' and no preamble or explanation. <|eot_id|><|start_header_id|>user<|end_header_id|>\n",
    "    Here are the facts:\n",
    "    \\n ------- \\n\n",
    "    {documents}\n",
    "    \\n ------- \\n\n",
    "    Here is the answer: {generation}  <|eot_id|><|start_header_id|>assistant<|end_header_id|>\"\"\",\n",
    "    input_variables=[\"generation\", \"documents\"],\n",
    ")\n",
    "\n",
    "hallucination_grader = prompt | llm | JsonOutputParser()\n",
    "hallucination_grader.invoke({\"documents\": docs, \"generation\": generation})"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "EDpl6fm3HJ9_",
    "tags": []
   },
   "source": [
    "## Answer Grader\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 95,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "yvx8L0z0HJ-A",
    "outputId": "5e77abb4-50c2-4daf-d6f8-d39393bdd68c"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'score': 'yes'}"
      ]
     },
     "execution_count": 95,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# LLM\n",
    "llm = ChatOllama(model=local_llm, format=\"json\", temperature=0)\n",
    "\n",
    "# Prompt\n",
    "prompt = PromptTemplate(\n",
    "    template=\"\"\"<|begin_of_text|><|start_header_id|>system<|end_header_id|> You are a grader assessing whether an\n",
    "    answer is useful to resolve a question. Give a binary score 'yes' or 'no' to indicate whether the answer is\n",
    "    useful to resolve a question. Provide the binary score as a JSON with a single key 'score' and no preamble or explanation.\n",
    "     <|eot_id|><|start_header_id|>user<|end_header_id|> Here is the answer:\n",
    "    \\n ------- \\n\n",
    "    {generation}\n",
    "    \\n ------- \\n\n",
    "    Here is the question: {question} <|eot_id|><|start_header_id|>assistant<|end_header_id|>\"\"\",\n",
    "    input_variables=[\"generation\", \"question\"],\n",
    ")\n",
    "\n",
    "answer_grader = prompt | llm | JsonOutputParser()\n",
    "answer_grader.invoke({\"question\": question,\"generation\": generation})"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "-VIDnsOTHJ-A",
    "tags": []
   },
   "source": [
    "## Control Flow in LangGraph\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 96,
   "metadata": {
    "id": "OEB6YmEPHJ-A"
   },
   "outputs": [],
   "source": [
    "### State\n",
    "\n",
    "class GraphState(TypedDict):\n",
    "    \"\"\"\n",
    "    Represents the state of our graph.\n",
    "\n",
    "    Attributes:\n",
    "        question: question\n",
    "        generation: LLM generation\n",
    "        documents: list of documents\n",
    "    \"\"\"\n",
    "    question : str\n",
    "    generation : str\n",
    "    documents : List[str]\n",
    "\n",
    "### Nodes\n",
    "\n",
    "def retrieve(state):\n",
    "    \"\"\"\n",
    "    Retrieve documents from vectorstore\n",
    "\n",
    "    Args:\n",
    "        state (dict): The current graph state\n",
    "\n",
    "    Returns:\n",
    "        state (dict): New key added to state, documents, that contains retrieved documents\n",
    "    \"\"\"\n",
    "    print(\"---RETRIEVE---\")\n",
    "    question = state[\"question\"]\n",
    "\n",
    "    # Retrieval\n",
    "    documents = retriever.invoke(question)\n",
    "    return {\"documents\": documents, \"question\": question}\n",
    "\n",
    "def generate(state):\n",
    "    \"\"\"\n",
    "    Generate answer using RAG on retrieved documents\n",
    "\n",
    "    Args:\n",
    "        state (dict): The current graph state\n",
    "\n",
    "    Returns:\n",
    "        state (dict): New key added to state, generation, that contains LLM generation\n",
    "    \"\"\"\n",
    "    print(\"---GENERATE---\")\n",
    "    question = state[\"question\"]\n",
    "    documents = state[\"documents\"]\n",
    "\n",
    "    # RAG generation\n",
    "    generation = rag_chain.invoke({\"context\": documents, \"question\": question})\n",
    "    return {\"documents\": documents, \"question\": question, \"generation\": generation}\n",
    "\n",
    "def grade_documents(state):\n",
    "    \"\"\"\n",
    "    Determines whether the retrieved documents are relevant to the question\n",
    "\n",
    "    Args:\n",
    "        state (dict): The current graph state\n",
    "\n",
    "    Returns:\n",
    "        state (dict): Filtered out irrelevant documents\n",
    "    \"\"\"\n",
    "\n",
    "    print(\"---CHECK DOCUMENT RELEVANCE TO QUESTION---\")\n",
    "    question = state[\"question\"]\n",
    "    documents = state[\"documents\"]\n",
    "\n",
    "    # Score each doc\n",
    "    filtered_docs = []\n",
    "    for d in documents:\n",
    "        score = retrieval_grader.invoke({\"question\": question, \"document\": d.page_content})\n",
    "        grade = score['score']\n",
    "        # Document relevant\n",
    "        if grade.lower() == \"yes\":\n",
    "            print(\"---GRADE: DOCUMENT RELEVANT---\")\n",
    "            filtered_docs.append(d)\n",
    "        # Document not relevant\n",
    "        else:\n",
    "            print(\"---GRADE: DOCUMENT NOT RELEVANT---\")\n",
    "            continue\n",
    "    return {\"documents\": filtered_docs, \"question\": question}\n",
    "\n",
    "\n",
    "def route_question(state):\n",
    "    \"\"\"\n",
    "    Route question to web search or RAG.\n",
    "\n",
    "    Args:\n",
    "        state (dict): The current graph state\n",
    "\n",
    "    Returns:\n",
    "        str: Next node to call\n",
    "    \"\"\"\n",
    "\n",
    "    print(\"---ROUTE QUESTION---\")\n",
    "    question = state[\"question\"]\n",
    "    print(question)\n",
    "\n",
    "\n",
    "def decide_to_generate(state):\n",
    "    \"\"\"\n",
    "    Determines whether to generate an answer\n",
    "\n",
    "    Args:\n",
    "        state (dict): The current graph state\n",
    "\n",
    "    Returns:\n",
    "        str: Binary decision for next node to call\n",
    "    \"\"\"\n",
    "\n",
    "    print(\"---ASSESS GRADED DOCUMENTS---\")\n",
    "    question = state[\"question\"]\n",
    "    filtered_documents = state[\"documents\"]\n",
    "\n",
    "    # We have relevant documents, so generate answer\n",
    "    print(\"---DECISION: GENERATE---\")\n",
    "    return \"generate\"\n",
    "\n",
    "def grade_generation_v_documents_and_question(state):\n",
    "    \"\"\"\n",
    "    Determines whether the generation is grounded in the document and answers question.\n",
    "\n",
    "    Args:\n",
    "        state (dict): The current graph state\n",
    "\n",
    "    Returns:\n",
    "        str: Decision for next node to call\n",
    "    \"\"\"\n",
    "\n",
    "    print(\"---CHECK HALLUCINATIONS---\")\n",
    "    question = state[\"question\"]\n",
    "    documents = state[\"documents\"]\n",
    "    generation = state[\"generation\"]\n",
    "\n",
    "    score = hallucination_grader.invoke({\"documents\": documents, \"generation\": generation})\n",
    "    grade = score['score']\n",
    "\n",
    "    # Check hallucination\n",
    "    if grade == \"yes\":\n",
    "        print(\"---DECISION: GENERATION IS GROUNDED IN DOCUMENTS---\")\n",
    "        # Check question-answering\n",
    "        print(\"---GRADE GENERATION vs QUESTION---\")\n",
    "        score = answer_grader.invoke({\"question\": question,\"generation\": generation})\n",
    "        grade = score['score']\n",
    "        if grade == \"yes\":\n",
    "            print(\"---DECISION: GENERATION ADDRESSES QUESTION---\")\n",
    "            return \"useful\"\n",
    "        else:\n",
    "            print(\"---DECISION: GENERATION DOES NOT ADDRESS QUESTION---\")\n",
    "            return \"not useful\"\n",
    "    else:\n",
    "        pprint(\"---DECISION: GENERATION IS NOT GROUNDED IN DOCUMENTS, RE-TRY---\")\n",
    "        return \"not supported\"\n",
    "\n",
    "workflow = StateGraph(GraphState)\n",
    "\n",
    "# Define the nodes\n",
    "workflow.add_node(\"route_question\", route_question) # route question\n",
    "workflow.add_node(\"retrieve\", retrieve) # retrieve\n",
    "workflow.add_node(\"grade_documents\", grade_documents) # grade documents\n",
    "workflow.add_node(\"generate\", generate) # generate"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "fR3qZzdnHJ-B",
    "tags": []
   },
   "source": [
    "## Build Graph"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 97,
   "metadata": {
    "id": "ACdQZHvEHJ-B"
   },
   "outputs": [],
   "source": [
    "# Build graph\n",
    "workflow.set_entry_point(\"route_question\")\n",
    "workflow.add_edge(\"route_question\", \"retrieve\")\n",
    "workflow.add_edge(\"retrieve\", \"grade_documents\")\n",
    "workflow.add_conditional_edges(\n",
    "    \"grade_documents\",\n",
    "    decide_to_generate,\n",
    "    {\n",
    "        \"generate\": \"generate\",\n",
    "    },\n",
    ")\n",
    "workflow.add_conditional_edges(\n",
    "    \"generate\",\n",
    "    grade_generation_v_documents_and_question,\n",
    "    {\n",
    "        \"not supported\": \"generate\",\n",
    "        \"useful\": END,\n",
    "        \"not useful\": \"retrieve\",\n",
    "    },\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "kg03HpycHJ-B",
    "tags": []
   },
   "source": [
    "## Compile & Test"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 98,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "Bq-AJvoAHJ-B",
    "outputId": "ac745ab7-e3cc-4f22-d48a-5d7ae4cc54db"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "---ROUTE QUESTION---\n",
      "My name is Sanjay. I will be visiting Chicago in summer with my family to explore and would like to go to interesting places.\n",
      "---RETRIEVE---\n",
      "'Finished running: retrieve:'\n",
      "---CHECK DOCUMENT RELEVANCE TO QUESTION---\n",
      "---GRADE: DOCUMENT RELEVANT---\n",
      "---GRADE: DOCUMENT RELEVANT---\n",
      "---GRADE: DOCUMENT RELEVANT---\n",
      "---GRADE: DOCUMENT RELEVANT---\n",
      "---ASSESS GRADED DOCUMENTS---\n",
      "---DECISION: GENERATE---\n",
      "'Finished running: grade_documents:'\n",
      "---GENERATE---\n",
      "---CHECK HALLUCINATIONS---\n",
      "---DECISION: GENERATION IS GROUNDED IN DOCUMENTS---\n",
      "---GRADE GENERATION vs QUESTION---\n",
      "---DECISION: GENERATION ADDRESSES QUESTION---\n",
      "'Finished running: generate:'\n",
      "(\"Sanjay! Welcome to Chicago in the summer! I'm Ateema, your AI tour guide. \"\n",
      " \"I've got some fantastic recommendations for you and your family to enjoy the \"\n",
      " \"city's beautiful beaches and more.\\n\"\n",
      " '\\n'\n",
      " \"As you're looking for interesting places to visit, I'll give you my top 10 \"\n",
      " 'picks, ranked from 1 to 10. Here they are:\\n'\n",
      " '\\n'\n",
      " '**Rank 1: North Avenue Beach**\\n'\n",
      " \"Start your beach-hopping adventure at North Avenue Beach, one of Chicago's \"\n",
      " 'most popular spots. Enjoy the sun, sand, and stunning views of Lake '\n",
      " 'Michigan. You can even take a dip in the lake or try your hand at surfing!\\n'\n",
      " '\\n'\n",
      " '**Rank 2: Oak Street Beach**\\n'\n",
      " 'Next up is Oak Street Beach, a hidden gem with plenty of room to spread out '\n",
      " 'and soak up the sun. Take a stroll along the beachfront path, grab a snack '\n",
      " 'from one of the many food vendors, and enjoy the lively atmosphere.\\n'\n",
      " '\\n'\n",
      " '**Rank 3: Montrose Beach**\\n'\n",
      " 'Montrose Beach is another must-visit spot for beach lovers. With its '\n",
      " \"picturesque views and calm waters, it's perfect for families or those \"\n",
      " \"looking to relax. Don't miss the nearby Montrose Dog Beach, where your furry \"\n",
      " 'friends can run free!\\n'\n",
      " '\\n'\n",
      " '**Rank 4: Belmont Harbor Beach**\\n'\n",
      " 'Belmont Harbor Beach offers a unique experience with its scenic harbor views '\n",
      " 'and tranquil atmosphere. Take a leisurely walk along the beachfront path, '\n",
      " 'grab a bite to eat at one of the many restaurants, or simply sit back and '\n",
      " 'enjoy the sunset.\\n'\n",
      " '\\n'\n",
      " '**Rank 5: Foster Beach**\\n'\n",
      " 'Foster Beach is a local favorite, known for its soft sand and calm waters. '\n",
      " \"It's an excellent spot for swimming, sunbathing, or trying your hand at \"\n",
      " \"beach volleyball. Don't miss the nearby Foster Avenue Beach House, offering \"\n",
      " 'food, drinks, and beach gear rentals.\\n'\n",
      " '\\n'\n",
      " '**Rank 6: Hollywood Beach**\\n'\n",
      " 'Hollywood Beach is a family-friendly destination with plenty of room to play '\n",
      " 'and relax. Enjoy the playground, splash pad, and picnic areas while taking '\n",
      " 'in the beautiful views of Lake Michigan.\\n'\n",
      " '\\n'\n",
      " '**Rank 7: Rainbow Beach**\\n'\n",
      " 'Rainbow Beach is a vibrant spot with a colorful beachfront path and plenty '\n",
      " 'of activities for all ages. Take a stroll along the lakefront trail, grab a '\n",
      " 'snack from one of the many food vendors, or simply enjoy the lively '\n",
      " 'atmosphere.\\n'\n",
      " '\\n'\n",
      " '**Rank 8: Ohio Street Beach**\\n'\n",
      " 'Ohio Street Beach is another popular spot with its wide stretch of sand and '\n",
      " 'calm waters. Enjoy swimming, sunbathing, or trying your hand at beach games '\n",
      " 'like volleyball or frisbee.\\n'\n",
      " '\\n'\n",
      " '**Rank 9: 57th Street Beach**\\n'\n",
      " '57th Street Beach is a hidden gem with plenty of room to spread out and '\n",
      " 'enjoy the views. Take a stroll along the lakefront path, grab a snack from '\n",
      " 'one of the many food vendors, or simply sit back and relax.\\n'\n",
      " '\\n'\n",
      " '**Rank 10: 31st Street Beach**\\n'\n",
      " 'Last but not least, we have 31st Street Beach, a quiet spot perfect for '\n",
      " 'those looking to unwind. Enjoy the peaceful atmosphere, take a stroll along '\n",
      " 'the lakefront path, or simply sit back and soak up the sun.\\n'\n",
      " '\\n'\n",
      " \"And that's it, Sanjay! These are my top 10 picks for Chicago's beautiful \"\n",
      " \"beaches. Whether you're looking for adventure, relaxation, or family fun, \"\n",
      " \"there's something for everyone in this amazing city. Enjoy your summer in \"\n",
      " 'Chicago!\\n'\n",
      " '\\n'\n",
      " '(End of prompt)')\n"
     ]
    }
   ],
   "source": [
    "# Compile\n",
    "app = workflow.compile()\n",
    "\n",
    "# Test\n",
    "inputs = {\"question\": \"My name is Sanjay. I will be visiting Chicago in summer with my family to explore and would like to go to interesting places.\"}\n",
    "for output in app.stream(inputs):\n",
    "    for key, value in output.items():\n",
    "        pprint(f\"Finished running: {key}:\")\n",
    "pprint(value[\"generation\"])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "p59gEpocfqWj"
   },
   "source": [
    "# SadTalker Avatar video generation + edge_tss text-to-audio-Setup"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 99,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "Kkk-2u0jf82d",
    "outputId": "cf25115a-6890-49fb-9b4a-61d4e8267177"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Requirement already satisfied: numpy in /usr/local/lib/python3.10/dist-packages (1.25.2)\n",
      "Requirement already satisfied: scipy in /usr/local/lib/python3.10/dist-packages (1.11.4)\n",
      "Requirement already satisfied: pillow in /usr/local/lib/python3.10/dist-packages (9.4.0)\n",
      "Requirement already satisfied: opencv-python-headless in /usr/local/lib/python3.10/dist-packages (4.9.0.80)\n",
      "Requirement already satisfied: scikit-image in /usr/local/lib/python3.10/dist-packages (0.19.3)\n",
      "Requirement already satisfied: networkx>=2.2 in /usr/local/lib/python3.10/dist-packages (from scikit-image) (3.3)\n",
      "Requirement already satisfied: imageio>=2.4.1 in /usr/local/lib/python3.10/dist-packages (from scikit-image) (2.31.6)\n",
      "Requirement already satisfied: tifffile>=2019.7.26 in /usr/local/lib/python3.10/dist-packages (from scikit-image) (2024.5.10)\n",
      "Requirement already satisfied: PyWavelets>=1.1.1 in /usr/local/lib/python3.10/dist-packages (from scikit-image) (1.6.0)\n",
      "Requirement already satisfied: packaging>=20.0 in /usr/local/lib/python3.10/dist-packages (from scikit-image) (23.2)\n",
      "Requirement already satisfied: gdown in /usr/local/lib/python3.10/dist-packages (5.1.0)\n",
      "Collecting paramiko\n",
      "  Downloading paramiko-3.4.0-py3-none-any.whl (225 kB)\n",
      "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m225.9/225.9 kB\u001b[0m \u001b[31m6.7 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
      "\u001b[?25hRequirement already satisfied: beautifulsoup4 in /usr/local/lib/python3.10/dist-packages (from gdown) (4.12.3)\n",
      "Requirement already satisfied: filelock in /usr/local/lib/python3.10/dist-packages (from gdown) (3.14.0)\n",
      "Requirement already satisfied: requests[socks] in /usr/local/lib/python3.10/dist-packages (from gdown) (2.31.0)\n",
      "Requirement already satisfied: tqdm in /usr/local/lib/python3.10/dist-packages (from gdown) (4.66.4)\n",
      "Requirement already satisfied: bcrypt>=3.2 in /usr/local/lib/python3.10/dist-packages (from paramiko) (4.1.3)\n",
      "Requirement already satisfied: cryptography>=3.3 in /usr/local/lib/python3.10/dist-packages (from paramiko) (42.0.7)\n",
      "Collecting pynacl>=1.5 (from paramiko)\n",
      "  Downloading PyNaCl-1.5.0-cp36-abi3-manylinux_2_17_x86_64.manylinux2014_x86_64.manylinux_2_24_x86_64.whl (856 kB)\n",
      "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m856.7/856.7 kB\u001b[0m \u001b[31m45.6 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
      "\u001b[?25hRequirement already satisfied: cffi>=1.12 in /usr/local/lib/python3.10/dist-packages (from cryptography>=3.3->paramiko) (1.16.0)\n",
      "Requirement already satisfied: soupsieve>1.2 in /usr/local/lib/python3.10/dist-packages (from beautifulsoup4->gdown) (2.5)\n",
      "Requirement already satisfied: charset-normalizer<4,>=2 in /usr/local/lib/python3.10/dist-packages (from requests[socks]->gdown) (3.3.2)\n",
      "Requirement already satisfied: idna<4,>=2.5 in /usr/local/lib/python3.10/dist-packages (from requests[socks]->gdown) (3.7)\n",
      "Requirement already satisfied: urllib3<3,>=1.21.1 in /usr/local/lib/python3.10/dist-packages (from requests[socks]->gdown) (2.0.7)\n",
      "Requirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.10/dist-packages (from requests[socks]->gdown) (2024.2.2)\n",
      "Requirement already satisfied: PySocks!=1.5.7,>=1.5.6 in /usr/local/lib/python3.10/dist-packages (from requests[socks]->gdown) (1.7.1)\n",
      "Requirement already satisfied: pycparser in /usr/local/lib/python3.10/dist-packages (from cffi>=1.12->cryptography>=3.3->paramiko) (2.22)\n",
      "Installing collected packages: pynacl, paramiko\n",
      "Successfully installed paramiko-3.4.0 pynacl-1.5.0\n",
      "Collecting kornia\n",
      "  Downloading kornia-0.7.2-py2.py3-none-any.whl (825 kB)\n",
      "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m825.4/825.4 kB\u001b[0m \u001b[31m18.7 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
      "\u001b[?25hCollecting kornia-rs>=0.1.0 (from kornia)\n",
      "  Downloading kornia_rs-0.1.3-cp310-cp310-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (2.4 MB)\n",
      "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m2.4/2.4 MB\u001b[0m \u001b[31m75.7 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
      "\u001b[?25hRequirement already satisfied: packaging in /usr/local/lib/python3.10/dist-packages (from kornia) (23.2)\n",
      "Requirement already satisfied: torch>=1.9.1 in /usr/local/lib/python3.10/dist-packages (from kornia) (2.2.1+cu121)\n",
      "Requirement already satisfied: filelock in /usr/local/lib/python3.10/dist-packages (from torch>=1.9.1->kornia) (3.14.0)\n",
      "Requirement already satisfied: typing-extensions>=4.8.0 in /usr/local/lib/python3.10/dist-packages (from torch>=1.9.1->kornia) (4.11.0)\n",
      "Requirement already satisfied: sympy in /usr/local/lib/python3.10/dist-packages (from torch>=1.9.1->kornia) (1.12)\n",
      "Requirement already satisfied: networkx in /usr/local/lib/python3.10/dist-packages (from torch>=1.9.1->kornia) (3.3)\n",
      "Requirement already satisfied: jinja2 in /usr/local/lib/python3.10/dist-packages (from torch>=1.9.1->kornia) (3.1.4)\n",
      "Requirement already satisfied: fsspec in /usr/local/lib/python3.10/dist-packages (from torch>=1.9.1->kornia) (2023.6.0)\n",
      "Collecting nvidia-cuda-nvrtc-cu12==12.1.105 (from torch>=1.9.1->kornia)\n",
      "  Using cached nvidia_cuda_nvrtc_cu12-12.1.105-py3-none-manylinux1_x86_64.whl (23.7 MB)\n",
      "Collecting nvidia-cuda-runtime-cu12==12.1.105 (from torch>=1.9.1->kornia)\n",
      "  Using cached nvidia_cuda_runtime_cu12-12.1.105-py3-none-manylinux1_x86_64.whl (823 kB)\n",
      "Collecting nvidia-cuda-cupti-cu12==12.1.105 (from torch>=1.9.1->kornia)\n",
      "  Using cached nvidia_cuda_cupti_cu12-12.1.105-py3-none-manylinux1_x86_64.whl (14.1 MB)\n",
      "Collecting nvidia-cudnn-cu12==8.9.2.26 (from torch>=1.9.1->kornia)\n",
      "  Using cached nvidia_cudnn_cu12-8.9.2.26-py3-none-manylinux1_x86_64.whl (731.7 MB)\n",
      "Collecting nvidia-cublas-cu12==12.1.3.1 (from torch>=1.9.1->kornia)\n",
      "  Using cached nvidia_cublas_cu12-12.1.3.1-py3-none-manylinux1_x86_64.whl (410.6 MB)\n",
      "Collecting nvidia-cufft-cu12==11.0.2.54 (from torch>=1.9.1->kornia)\n",
      "  Using cached nvidia_cufft_cu12-11.0.2.54-py3-none-manylinux1_x86_64.whl (121.6 MB)\n",
      "Collecting nvidia-curand-cu12==10.3.2.106 (from torch>=1.9.1->kornia)\n",
      "  Using cached nvidia_curand_cu12-10.3.2.106-py3-none-manylinux1_x86_64.whl (56.5 MB)\n",
      "Collecting nvidia-cusolver-cu12==11.4.5.107 (from torch>=1.9.1->kornia)\n",
      "  Using cached nvidia_cusolver_cu12-11.4.5.107-py3-none-manylinux1_x86_64.whl (124.2 MB)\n",
      "Collecting nvidia-cusparse-cu12==12.1.0.106 (from torch>=1.9.1->kornia)\n",
      "  Using cached nvidia_cusparse_cu12-12.1.0.106-py3-none-manylinux1_x86_64.whl (196.0 MB)\n",
      "Collecting nvidia-nccl-cu12==2.19.3 (from torch>=1.9.1->kornia)\n",
      "  Using cached nvidia_nccl_cu12-2.19.3-py3-none-manylinux1_x86_64.whl (166.0 MB)\n",
      "Collecting nvidia-nvtx-cu12==12.1.105 (from torch>=1.9.1->kornia)\n",
      "  Using cached nvidia_nvtx_cu12-12.1.105-py3-none-manylinux1_x86_64.whl (99 kB)\n",
      "Requirement already satisfied: triton==2.2.0 in /usr/local/lib/python3.10/dist-packages (from torch>=1.9.1->kornia) (2.2.0)\n",
      "Collecting nvidia-nvjitlink-cu12 (from nvidia-cusolver-cu12==11.4.5.107->torch>=1.9.1->kornia)\n",
      "  Using cached nvidia_nvjitlink_cu12-12.4.127-py3-none-manylinux2014_x86_64.whl (21.1 MB)\n",
      "Requirement already satisfied: MarkupSafe>=2.0 in /usr/local/lib/python3.10/dist-packages (from jinja2->torch>=1.9.1->kornia) (2.1.5)\n",
      "Requirement already satisfied: mpmath>=0.19 in /usr/local/lib/python3.10/dist-packages (from sympy->torch>=1.9.1->kornia) (1.3.0)\n",
      "Installing collected packages: nvidia-nvtx-cu12, nvidia-nvjitlink-cu12, nvidia-nccl-cu12, nvidia-curand-cu12, nvidia-cufft-cu12, nvidia-cuda-runtime-cu12, nvidia-cuda-nvrtc-cu12, nvidia-cuda-cupti-cu12, nvidia-cublas-cu12, kornia-rs, nvidia-cusparse-cu12, nvidia-cudnn-cu12, nvidia-cusolver-cu12, kornia\n",
      "Successfully installed kornia-0.7.2 kornia-rs-0.1.3 nvidia-cublas-cu12-12.1.3.1 nvidia-cuda-cupti-cu12-12.1.105 nvidia-cuda-nvrtc-cu12-12.1.105 nvidia-cuda-runtime-cu12-12.1.105 nvidia-cudnn-cu12-8.9.2.26 nvidia-cufft-cu12-11.0.2.54 nvidia-curand-cu12-10.3.2.106 nvidia-cusolver-cu12-11.4.5.107 nvidia-cusparse-cu12-12.1.0.106 nvidia-nccl-cu12-2.19.3 nvidia-nvjitlink-cu12-12.4.127 nvidia-nvtx-cu12-12.1.105\n",
      "Collecting yacs\n",
      "  Downloading yacs-0.1.8-py3-none-any.whl (14 kB)\n",
      "Requirement already satisfied: PyYAML in /usr/local/lib/python3.10/dist-packages (from yacs) (6.0.1)\n",
      "Installing collected packages: yacs\n",
      "Successfully installed yacs-0.1.8\n",
      "Collecting gfpgan\n",
      "  Downloading gfpgan-1.3.8-py3-none-any.whl (52 kB)\n",
      "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m52.2/52.2 kB\u001b[0m \u001b[31m2.1 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
      "\u001b[?25hCollecting basicsr>=1.4.2 (from gfpgan)\n",
      "  Downloading basicsr-1.4.2.tar.gz (172 kB)\n",
      "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m172.5/172.5 kB\u001b[0m \u001b[31m7.5 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
      "\u001b[?25h  Preparing metadata (setup.py) ... \u001b[?25l\u001b[?25hdone\n",
      "Collecting facexlib>=0.2.5 (from gfpgan)\n",
      "  Downloading facexlib-0.3.0-py3-none-any.whl (59 kB)\n",
      "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m59.6/59.6 kB\u001b[0m \u001b[31m9.5 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
      "\u001b[?25hCollecting lmdb (from gfpgan)\n",
      "  Downloading lmdb-1.4.1-cp310-cp310-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (299 kB)\n",
      "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m299.2/299.2 kB\u001b[0m \u001b[31m34.0 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
      "\u001b[?25hRequirement already satisfied: numpy in /usr/local/lib/python3.10/dist-packages (from gfpgan) (1.25.2)\n",
      "Requirement already satisfied: opencv-python in /usr/local/lib/python3.10/dist-packages (from gfpgan) (4.8.0.76)\n",
      "Requirement already satisfied: pyyaml in /usr/local/lib/python3.10/dist-packages (from gfpgan) (6.0.1)\n",
      "Requirement already satisfied: scipy in /usr/local/lib/python3.10/dist-packages (from gfpgan) (1.11.4)\n",
      "Collecting tb-nightly (from gfpgan)\n",
      "  Downloading tb_nightly-2.17.0a20240520-py3-none-any.whl (5.5 MB)\n",
      "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m5.5/5.5 MB\u001b[0m \u001b[31m99.3 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
      "\u001b[?25hRequirement already satisfied: torch>=1.7 in /usr/local/lib/python3.10/dist-packages (from gfpgan) (2.2.1+cu121)\n",
      "Requirement already satisfied: torchvision in /usr/local/lib/python3.10/dist-packages (from gfpgan) (0.17.1+cu121)\n",
      "Requirement already satisfied: tqdm in /usr/local/lib/python3.10/dist-packages (from gfpgan) (4.66.4)\n",
      "Collecting yapf (from gfpgan)\n",
      "  Downloading yapf-0.40.2-py3-none-any.whl (254 kB)\n",
      "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m254.7/254.7 kB\u001b[0m \u001b[31m33.5 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
      "\u001b[?25hCollecting addict (from basicsr>=1.4.2->gfpgan)\n",
      "  Downloading addict-2.4.0-py3-none-any.whl (3.8 kB)\n",
      "Requirement already satisfied: future in /usr/local/lib/python3.10/dist-packages (from basicsr>=1.4.2->gfpgan) (0.18.3)\n",
      "Requirement already satisfied: Pillow in /usr/local/lib/python3.10/dist-packages (from basicsr>=1.4.2->gfpgan) (9.4.0)\n",
      "Requirement already satisfied: requests in /usr/local/lib/python3.10/dist-packages (from basicsr>=1.4.2->gfpgan) (2.31.0)\n",
      "Requirement already satisfied: scikit-image in /usr/local/lib/python3.10/dist-packages (from basicsr>=1.4.2->gfpgan) (0.19.3)\n",
      "Collecting filterpy (from facexlib>=0.2.5->gfpgan)\n",
      "  Downloading filterpy-1.4.5.zip (177 kB)\n",
      "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m178.0/178.0 kB\u001b[0m \u001b[31m25.6 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
      "\u001b[?25h  Preparing metadata (setup.py) ... \u001b[?25l\u001b[?25hdone\n",
      "Requirement already satisfied: numba in /usr/local/lib/python3.10/dist-packages (from facexlib>=0.2.5->gfpgan) (0.58.1)\n",
      "Requirement already satisfied: filelock in /usr/local/lib/python3.10/dist-packages (from torch>=1.7->gfpgan) (3.14.0)\n",
      "Requirement already satisfied: typing-extensions>=4.8.0 in /usr/local/lib/python3.10/dist-packages (from torch>=1.7->gfpgan) (4.11.0)\n",
      "Requirement already satisfied: sympy in /usr/local/lib/python3.10/dist-packages (from torch>=1.7->gfpgan) (1.12)\n",
      "Requirement already satisfied: networkx in /usr/local/lib/python3.10/dist-packages (from torch>=1.7->gfpgan) (3.3)\n",
      "Requirement already satisfied: jinja2 in /usr/local/lib/python3.10/dist-packages (from torch>=1.7->gfpgan) (3.1.4)\n",
      "Requirement already satisfied: fsspec in /usr/local/lib/python3.10/dist-packages (from torch>=1.7->gfpgan) (2023.6.0)\n",
      "Requirement already satisfied: nvidia-cuda-nvrtc-cu12==12.1.105 in /usr/local/lib/python3.10/dist-packages (from torch>=1.7->gfpgan) (12.1.105)\n",
      "Requirement already satisfied: nvidia-cuda-runtime-cu12==12.1.105 in /usr/local/lib/python3.10/dist-packages (from torch>=1.7->gfpgan) (12.1.105)\n",
      "Requirement already satisfied: nvidia-cuda-cupti-cu12==12.1.105 in /usr/local/lib/python3.10/dist-packages (from torch>=1.7->gfpgan) (12.1.105)\n",
      "Requirement already satisfied: nvidia-cudnn-cu12==8.9.2.26 in /usr/local/lib/python3.10/dist-packages (from torch>=1.7->gfpgan) (8.9.2.26)\n",
      "Requirement already satisfied: nvidia-cublas-cu12==12.1.3.1 in /usr/local/lib/python3.10/dist-packages (from torch>=1.7->gfpgan) (12.1.3.1)\n",
      "Requirement already satisfied: nvidia-cufft-cu12==11.0.2.54 in /usr/local/lib/python3.10/dist-packages (from torch>=1.7->gfpgan) (11.0.2.54)\n",
      "Requirement already satisfied: nvidia-curand-cu12==10.3.2.106 in /usr/local/lib/python3.10/dist-packages (from torch>=1.7->gfpgan) (10.3.2.106)\n",
      "Requirement already satisfied: nvidia-cusolver-cu12==11.4.5.107 in /usr/local/lib/python3.10/dist-packages (from torch>=1.7->gfpgan) (11.4.5.107)\n",
      "Requirement already satisfied: nvidia-cusparse-cu12==12.1.0.106 in /usr/local/lib/python3.10/dist-packages (from torch>=1.7->gfpgan) (12.1.0.106)\n",
      "Requirement already satisfied: nvidia-nccl-cu12==2.19.3 in /usr/local/lib/python3.10/dist-packages (from torch>=1.7->gfpgan) (2.19.3)\n",
      "Requirement already satisfied: nvidia-nvtx-cu12==12.1.105 in /usr/local/lib/python3.10/dist-packages (from torch>=1.7->gfpgan) (12.1.105)\n",
      "Requirement already satisfied: triton==2.2.0 in /usr/local/lib/python3.10/dist-packages (from torch>=1.7->gfpgan) (2.2.0)\n",
      "Requirement already satisfied: nvidia-nvjitlink-cu12 in /usr/local/lib/python3.10/dist-packages (from nvidia-cusolver-cu12==11.4.5.107->torch>=1.7->gfpgan) (12.4.127)\n",
      "Requirement already satisfied: absl-py>=0.4 in /usr/local/lib/python3.10/dist-packages (from tb-nightly->gfpgan) (1.4.0)\n",
      "Requirement already satisfied: grpcio>=1.48.2 in /usr/local/lib/python3.10/dist-packages (from tb-nightly->gfpgan) (1.63.0)\n",
      "Requirement already satisfied: markdown>=2.6.8 in /usr/local/lib/python3.10/dist-packages (from tb-nightly->gfpgan) (3.6)\n",
      "Requirement already satisfied: protobuf!=4.24.0,<5.0.0,>=3.19.6 in /usr/local/lib/python3.10/dist-packages (from tb-nightly->gfpgan) (3.20.3)\n",
      "Requirement already satisfied: setuptools>=41.0.0 in /usr/local/lib/python3.10/dist-packages (from tb-nightly->gfpgan) (67.7.2)\n",
      "Requirement already satisfied: six>1.9 in /usr/local/lib/python3.10/dist-packages (from tb-nightly->gfpgan) (1.16.0)\n",
      "Requirement already satisfied: tensorboard-data-server<0.8.0,>=0.7.0 in /usr/local/lib/python3.10/dist-packages (from tb-nightly->gfpgan) (0.7.2)\n",
      "Requirement already satisfied: werkzeug>=1.0.1 in /usr/local/lib/python3.10/dist-packages (from tb-nightly->gfpgan) (3.0.3)\n",
      "Requirement already satisfied: importlib-metadata>=6.6.0 in /usr/local/lib/python3.10/dist-packages (from yapf->gfpgan) (7.0.0)\n",
      "Requirement already satisfied: platformdirs>=3.5.1 in /usr/local/lib/python3.10/dist-packages (from yapf->gfpgan) (4.2.1)\n",
      "Requirement already satisfied: tomli>=2.0.1 in /usr/local/lib/python3.10/dist-packages (from yapf->gfpgan) (2.0.1)\n",
      "Requirement already satisfied: zipp>=0.5 in /usr/local/lib/python3.10/dist-packages (from importlib-metadata>=6.6.0->yapf->gfpgan) (3.18.1)\n",
      "Requirement already satisfied: MarkupSafe>=2.1.1 in /usr/local/lib/python3.10/dist-packages (from werkzeug>=1.0.1->tb-nightly->gfpgan) (2.1.5)\n",
      "Requirement already satisfied: matplotlib in /usr/local/lib/python3.10/dist-packages (from filterpy->facexlib>=0.2.5->gfpgan) (3.7.1)\n",
      "Requirement already satisfied: llvmlite<0.42,>=0.41.0dev0 in /usr/local/lib/python3.10/dist-packages (from numba->facexlib>=0.2.5->gfpgan) (0.41.1)\n",
      "Requirement already satisfied: charset-normalizer<4,>=2 in /usr/local/lib/python3.10/dist-packages (from requests->basicsr>=1.4.2->gfpgan) (3.3.2)\n",
      "Requirement already satisfied: idna<4,>=2.5 in /usr/local/lib/python3.10/dist-packages (from requests->basicsr>=1.4.2->gfpgan) (3.7)\n",
      "Requirement already satisfied: urllib3<3,>=1.21.1 in /usr/local/lib/python3.10/dist-packages (from requests->basicsr>=1.4.2->gfpgan) (2.0.7)\n",
      "Requirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.10/dist-packages (from requests->basicsr>=1.4.2->gfpgan) (2024.2.2)\n",
      "Requirement already satisfied: imageio>=2.4.1 in /usr/local/lib/python3.10/dist-packages (from scikit-image->basicsr>=1.4.2->gfpgan) (2.31.6)\n",
      "Requirement already satisfied: tifffile>=2019.7.26 in /usr/local/lib/python3.10/dist-packages (from scikit-image->basicsr>=1.4.2->gfpgan) (2024.5.10)\n",
      "Requirement already satisfied: PyWavelets>=1.1.1 in /usr/local/lib/python3.10/dist-packages (from scikit-image->basicsr>=1.4.2->gfpgan) (1.6.0)\n",
      "Requirement already satisfied: packaging>=20.0 in /usr/local/lib/python3.10/dist-packages (from scikit-image->basicsr>=1.4.2->gfpgan) (23.2)\n",
      "Requirement already satisfied: mpmath>=0.19 in /usr/local/lib/python3.10/dist-packages (from sympy->torch>=1.7->gfpgan) (1.3.0)\n",
      "Requirement already satisfied: contourpy>=1.0.1 in /usr/local/lib/python3.10/dist-packages (from matplotlib->filterpy->facexlib>=0.2.5->gfpgan) (1.2.1)\n",
      "Requirement already satisfied: cycler>=0.10 in /usr/local/lib/python3.10/dist-packages (from matplotlib->filterpy->facexlib>=0.2.5->gfpgan) (0.12.1)\n",
      "Requirement already satisfied: fonttools>=4.22.0 in /usr/local/lib/python3.10/dist-packages (from matplotlib->filterpy->facexlib>=0.2.5->gfpgan) (4.51.0)\n",
      "Requirement already satisfied: kiwisolver>=1.0.1 in /usr/local/lib/python3.10/dist-packages (from matplotlib->filterpy->facexlib>=0.2.5->gfpgan) (1.4.5)\n",
      "Requirement already satisfied: pyparsing>=2.3.1 in /usr/local/lib/python3.10/dist-packages (from matplotlib->filterpy->facexlib>=0.2.5->gfpgan) (3.1.2)\n",
      "Requirement already satisfied: python-dateutil>=2.7 in /usr/local/lib/python3.10/dist-packages (from matplotlib->filterpy->facexlib>=0.2.5->gfpgan) (2.8.2)\n",
      "Building wheels for collected packages: basicsr, filterpy\n",
      "  Building wheel for basicsr (setup.py) ... \u001b[?25l\u001b[?25hdone\n",
      "  Created wheel for basicsr: filename=basicsr-1.4.2-py3-none-any.whl size=214818 sha256=5b231bcd423b8c68322ebe4bf0ff2da17607a7d371a0fd907c2b3a948baad7c0\n",
      "  Stored in directory: /root/.cache/pip/wheels/38/83/99/2d8437cc652a01af27df5ff037a4075e95b52d67705c5f30ca\n",
      "  Building wheel for filterpy (setup.py) ... \u001b[?25l\u001b[?25hdone\n",
      "  Created wheel for filterpy: filename=filterpy-1.4.5-py3-none-any.whl size=110458 sha256=1e3557fcce7d2a314c85f0df8f529e5a0205c16a0d2cd601affa812f1cf4cdcf\n",
      "  Stored in directory: /root/.cache/pip/wheels/0f/0c/ea/218f266af4ad626897562199fbbcba521b8497303200186102\n",
      "Successfully built basicsr filterpy\n",
      "Installing collected packages: lmdb, addict, yapf, tb-nightly, filterpy, facexlib, basicsr, gfpgan\n",
      "Successfully installed addict-2.4.0 basicsr-1.4.2 facexlib-0.3.0 filterpy-1.4.5 gfpgan-1.3.8 lmdb-1.4.1 tb-nightly-2.17.0a20240520 yapf-0.40.2\n",
      "Collecting pydub\n",
      "  Downloading pydub-0.25.1-py2.py3-none-any.whl (32 kB)\n",
      "Installing collected packages: pydub\n",
      "Successfully installed pydub-0.25.1\n",
      "Requirement already satisfied: facexlib in /usr/local/lib/python3.10/dist-packages (0.3.0)\n",
      "Requirement already satisfied: filterpy in /usr/local/lib/python3.10/dist-packages (from facexlib) (1.4.5)\n",
      "Requirement already satisfied: numba in /usr/local/lib/python3.10/dist-packages (from facexlib) (0.58.1)\n",
      "Requirement already satisfied: numpy in /usr/local/lib/python3.10/dist-packages (from facexlib) (1.25.2)\n",
      "Requirement already satisfied: opencv-python in /usr/local/lib/python3.10/dist-packages (from facexlib) (4.8.0.76)\n",
      "Requirement already satisfied: Pillow in /usr/local/lib/python3.10/dist-packages (from facexlib) (9.4.0)\n",
      "Requirement already satisfied: scipy in /usr/local/lib/python3.10/dist-packages (from facexlib) (1.11.4)\n",
      "Requirement already satisfied: torch in /usr/local/lib/python3.10/dist-packages (from facexlib) (2.2.1+cu121)\n",
      "Requirement already satisfied: torchvision in /usr/local/lib/python3.10/dist-packages (from facexlib) (0.17.1+cu121)\n",
      "Requirement already satisfied: tqdm in /usr/local/lib/python3.10/dist-packages (from facexlib) (4.66.4)\n",
      "Requirement already satisfied: matplotlib in /usr/local/lib/python3.10/dist-packages (from filterpy->facexlib) (3.7.1)\n",
      "Requirement already satisfied: llvmlite<0.42,>=0.41.0dev0 in /usr/local/lib/python3.10/dist-packages (from numba->facexlib) (0.41.1)\n",
      "Requirement already satisfied: filelock in /usr/local/lib/python3.10/dist-packages (from torch->facexlib) (3.14.0)\n",
      "Requirement already satisfied: typing-extensions>=4.8.0 in /usr/local/lib/python3.10/dist-packages (from torch->facexlib) (4.11.0)\n",
      "Requirement already satisfied: sympy in /usr/local/lib/python3.10/dist-packages (from torch->facexlib) (1.12)\n",
      "Requirement already satisfied: networkx in /usr/local/lib/python3.10/dist-packages (from torch->facexlib) (3.3)\n",
      "Requirement already satisfied: jinja2 in /usr/local/lib/python3.10/dist-packages (from torch->facexlib) (3.1.4)\n",
      "Requirement already satisfied: fsspec in /usr/local/lib/python3.10/dist-packages (from torch->facexlib) (2023.6.0)\n",
      "Requirement already satisfied: nvidia-cuda-nvrtc-cu12==12.1.105 in /usr/local/lib/python3.10/dist-packages (from torch->facexlib) (12.1.105)\n",
      "Requirement already satisfied: nvidia-cuda-runtime-cu12==12.1.105 in /usr/local/lib/python3.10/dist-packages (from torch->facexlib) (12.1.105)\n",
      "Requirement already satisfied: nvidia-cuda-cupti-cu12==12.1.105 in /usr/local/lib/python3.10/dist-packages (from torch->facexlib) (12.1.105)\n",
      "Requirement already satisfied: nvidia-cudnn-cu12==8.9.2.26 in /usr/local/lib/python3.10/dist-packages (from torch->facexlib) (8.9.2.26)\n",
      "Requirement already satisfied: nvidia-cublas-cu12==12.1.3.1 in /usr/local/lib/python3.10/dist-packages (from torch->facexlib) (12.1.3.1)\n",
      "Requirement already satisfied: nvidia-cufft-cu12==11.0.2.54 in /usr/local/lib/python3.10/dist-packages (from torch->facexlib) (11.0.2.54)\n",
      "Requirement already satisfied: nvidia-curand-cu12==10.3.2.106 in /usr/local/lib/python3.10/dist-packages (from torch->facexlib) (10.3.2.106)\n",
      "Requirement already satisfied: nvidia-cusolver-cu12==11.4.5.107 in /usr/local/lib/python3.10/dist-packages (from torch->facexlib) (11.4.5.107)\n",
      "Requirement already satisfied: nvidia-cusparse-cu12==12.1.0.106 in /usr/local/lib/python3.10/dist-packages (from torch->facexlib) (12.1.0.106)\n",
      "Requirement already satisfied: nvidia-nccl-cu12==2.19.3 in /usr/local/lib/python3.10/dist-packages (from torch->facexlib) (2.19.3)\n",
      "Requirement already satisfied: nvidia-nvtx-cu12==12.1.105 in /usr/local/lib/python3.10/dist-packages (from torch->facexlib) (12.1.105)\n",
      "Requirement already satisfied: triton==2.2.0 in /usr/local/lib/python3.10/dist-packages (from torch->facexlib) (2.2.0)\n",
      "Requirement already satisfied: nvidia-nvjitlink-cu12 in /usr/local/lib/python3.10/dist-packages (from nvidia-cusolver-cu12==11.4.5.107->torch->facexlib) (12.4.127)\n",
      "Requirement already satisfied: MarkupSafe>=2.0 in /usr/local/lib/python3.10/dist-packages (from jinja2->torch->facexlib) (2.1.5)\n",
      "Requirement already satisfied: contourpy>=1.0.1 in /usr/local/lib/python3.10/dist-packages (from matplotlib->filterpy->facexlib) (1.2.1)\n",
      "Requirement already satisfied: cycler>=0.10 in /usr/local/lib/python3.10/dist-packages (from matplotlib->filterpy->facexlib) (0.12.1)\n",
      "Requirement already satisfied: fonttools>=4.22.0 in /usr/local/lib/python3.10/dist-packages (from matplotlib->filterpy->facexlib) (4.51.0)\n",
      "Requirement already satisfied: kiwisolver>=1.0.1 in /usr/local/lib/python3.10/dist-packages (from matplotlib->filterpy->facexlib) (1.4.5)\n",
      "Requirement already satisfied: packaging>=20.0 in /usr/local/lib/python3.10/dist-packages (from matplotlib->filterpy->facexlib) (23.2)\n",
      "Requirement already satisfied: pyparsing>=2.3.1 in /usr/local/lib/python3.10/dist-packages (from matplotlib->filterpy->facexlib) (3.1.2)\n",
      "Requirement already satisfied: python-dateutil>=2.7 in /usr/local/lib/python3.10/dist-packages (from matplotlib->filterpy->facexlib) (2.8.2)\n",
      "Requirement already satisfied: mpmath>=0.19 in /usr/local/lib/python3.10/dist-packages (from sympy->torch->facexlib) (1.3.0)\n",
      "Requirement already satisfied: six>=1.5 in /usr/local/lib/python3.10/dist-packages (from python-dateutil>=2.7->matplotlib->filterpy->facexlib) (1.16.0)\n",
      "Collecting torchaudio==2.0.0\n",
      "  Downloading torchaudio-2.0.0-cp310-cp310-manylinux1_x86_64.whl (4.4 MB)\n",
      "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m4.4/4.4 MB\u001b[0m \u001b[31m55.3 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
      "\u001b[?25hCollecting torch==2.0.0 (from torchaudio==2.0.0)\n",
      "  Downloading torch-2.0.0-cp310-cp310-manylinux1_x86_64.whl (619.9 MB)\n",
      "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m619.9/619.9 MB\u001b[0m \u001b[31m1.8 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
      "\u001b[?25hRequirement already satisfied: filelock in /usr/local/lib/python3.10/dist-packages (from torch==2.0.0->torchaudio==2.0.0) (3.14.0)\n",
      "Requirement already satisfied: typing-extensions in /usr/local/lib/python3.10/dist-packages (from torch==2.0.0->torchaudio==2.0.0) (4.11.0)\n",
      "Requirement already satisfied: sympy in /usr/local/lib/python3.10/dist-packages (from torch==2.0.0->torchaudio==2.0.0) (1.12)\n",
      "Requirement already satisfied: networkx in /usr/local/lib/python3.10/dist-packages (from torch==2.0.0->torchaudio==2.0.0) (3.3)\n",
      "Requirement already satisfied: jinja2 in /usr/local/lib/python3.10/dist-packages (from torch==2.0.0->torchaudio==2.0.0) (3.1.4)\n",
      "Collecting nvidia-cuda-nvrtc-cu11==11.7.99 (from torch==2.0.0->torchaudio==2.0.0)\n",
      "  Downloading nvidia_cuda_nvrtc_cu11-11.7.99-2-py3-none-manylinux1_x86_64.whl (21.0 MB)\n",
      "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m21.0/21.0 MB\u001b[0m \u001b[31m71.5 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
      "\u001b[?25hCollecting nvidia-cuda-runtime-cu11==11.7.99 (from torch==2.0.0->torchaudio==2.0.0)\n",
      "  Downloading nvidia_cuda_runtime_cu11-11.7.99-py3-none-manylinux1_x86_64.whl (849 kB)\n",
      "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m849.3/849.3 kB\u001b[0m \u001b[31m67.4 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
      "\u001b[?25hCollecting nvidia-cuda-cupti-cu11==11.7.101 (from torch==2.0.0->torchaudio==2.0.0)\n",
      "  Downloading nvidia_cuda_cupti_cu11-11.7.101-py3-none-manylinux1_x86_64.whl (11.8 MB)\n",
      "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m11.8/11.8 MB\u001b[0m \u001b[31m32.0 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
      "\u001b[?25hCollecting nvidia-cudnn-cu11==8.5.0.96 (from torch==2.0.0->torchaudio==2.0.0)\n",
      "  Downloading nvidia_cudnn_cu11-8.5.0.96-2-py3-none-manylinux1_x86_64.whl (557.1 MB)\n",
      "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m557.1/557.1 MB\u001b[0m \u001b[31m1.8 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
      "\u001b[?25hCollecting nvidia-cublas-cu11==11.10.3.66 (from torch==2.0.0->torchaudio==2.0.0)\n",
      "  Downloading nvidia_cublas_cu11-11.10.3.66-py3-none-manylinux1_x86_64.whl (317.1 MB)\n",
      "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m317.1/317.1 MB\u001b[0m \u001b[31m2.7 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
      "\u001b[?25hCollecting nvidia-cufft-cu11==10.9.0.58 (from torch==2.0.0->torchaudio==2.0.0)\n",
      "  Downloading nvidia_cufft_cu11-10.9.0.58-py3-none-manylinux1_x86_64.whl (168.4 MB)\n",
      "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m168.4/168.4 MB\u001b[0m \u001b[31m9.9 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
      "\u001b[?25hCollecting nvidia-curand-cu11==10.2.10.91 (from torch==2.0.0->torchaudio==2.0.0)\n",
      "  Downloading nvidia_curand_cu11-10.2.10.91-py3-none-manylinux1_x86_64.whl (54.6 MB)\n",
      "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m54.6/54.6 MB\u001b[0m \u001b[31m29.5 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
      "\u001b[?25hCollecting nvidia-cusolver-cu11==11.4.0.1 (from torch==2.0.0->torchaudio==2.0.0)\n",
      "  Downloading nvidia_cusolver_cu11-11.4.0.1-2-py3-none-manylinux1_x86_64.whl (102.6 MB)\n",
      "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m102.6/102.6 MB\u001b[0m \u001b[31m16.5 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
      "\u001b[?25hCollecting nvidia-cusparse-cu11==11.7.4.91 (from torch==2.0.0->torchaudio==2.0.0)\n",
      "  Downloading nvidia_cusparse_cu11-11.7.4.91-py3-none-manylinux1_x86_64.whl (173.2 MB)\n",
      "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m173.2/173.2 MB\u001b[0m \u001b[31m6.7 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
      "\u001b[?25hCollecting nvidia-nccl-cu11==2.14.3 (from torch==2.0.0->torchaudio==2.0.0)\n",
      "  Downloading nvidia_nccl_cu11-2.14.3-py3-none-manylinux1_x86_64.whl (177.1 MB)\n",
      "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m177.1/177.1 MB\u001b[0m \u001b[31m5.0 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
      "\u001b[?25hCollecting nvidia-nvtx-cu11==11.7.91 (from torch==2.0.0->torchaudio==2.0.0)\n",
      "  Downloading nvidia_nvtx_cu11-11.7.91-py3-none-manylinux1_x86_64.whl (98 kB)\n",
      "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m98.6/98.6 kB\u001b[0m \u001b[31m14.2 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
      "\u001b[?25hCollecting triton==2.0.0 (from torch==2.0.0->torchaudio==2.0.0)\n",
      "  Downloading triton-2.0.0-1-cp310-cp310-manylinux2014_x86_64.manylinux_2_17_x86_64.whl (63.3 MB)\n",
      "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m63.3/63.3 MB\u001b[0m \u001b[31m25.9 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
      "\u001b[?25hRequirement already satisfied: setuptools in /usr/local/lib/python3.10/dist-packages (from nvidia-cublas-cu11==11.10.3.66->torch==2.0.0->torchaudio==2.0.0) (67.7.2)\n",
      "Requirement already satisfied: wheel in /usr/local/lib/python3.10/dist-packages (from nvidia-cublas-cu11==11.10.3.66->torch==2.0.0->torchaudio==2.0.0) (0.43.0)\n",
      "Requirement already satisfied: cmake in /usr/local/lib/python3.10/dist-packages (from triton==2.0.0->torch==2.0.0->torchaudio==2.0.0) (3.27.9)\n",
      "Collecting lit (from triton==2.0.0->torch==2.0.0->torchaudio==2.0.0)\n",
      "  Downloading lit-18.1.6-py3-none-any.whl (96 kB)\n",
      "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m96.4/96.4 kB\u001b[0m \u001b[31m14.0 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
      "\u001b[?25hRequirement already satisfied: MarkupSafe>=2.0 in /usr/local/lib/python3.10/dist-packages (from jinja2->torch==2.0.0->torchaudio==2.0.0) (2.1.5)\n",
      "Requirement already satisfied: mpmath>=0.19 in /usr/local/lib/python3.10/dist-packages (from sympy->torch==2.0.0->torchaudio==2.0.0) (1.3.0)\n",
      "\u001b[33mWARNING: The candidate selected for download or install is a yanked version: 'torchaudio' candidate (version 2.0.0 at https://files.pythonhosted.org/packages/40/23/4c8e2553b70eb46eb6d6989ee124707305e7c077a1bd16403f99f95f6a33/torchaudio-2.0.0-cp310-cp310-manylinux1_x86_64.whl (from https://pypi.org/simple/torchaudio/))\n",
      "Reason for being yanked: Contains an incorrect torch dependency\u001b[0m\u001b[33m\n",
      "\u001b[0mInstalling collected packages: lit, nvidia-nvtx-cu11, nvidia-nccl-cu11, nvidia-cusparse-cu11, nvidia-curand-cu11, nvidia-cufft-cu11, nvidia-cuda-runtime-cu11, nvidia-cuda-nvrtc-cu11, nvidia-cuda-cupti-cu11, nvidia-cublas-cu11, nvidia-cusolver-cu11, nvidia-cudnn-cu11, triton, torch, torchaudio\n",
      "  Attempting uninstall: triton\n",
      "    Found existing installation: triton 2.2.0\n",
      "    Uninstalling triton-2.2.0:\n",
      "      Successfully uninstalled triton-2.2.0\n",
      "  Attempting uninstall: torch\n",
      "    Found existing installation: torch 2.2.1+cu121\n",
      "    Uninstalling torch-2.2.1+cu121:\n",
      "      Successfully uninstalled torch-2.2.1+cu121\n",
      "  Attempting uninstall: torchaudio\n",
      "    Found existing installation: torchaudio 2.2.1+cu121\n",
      "    Uninstalling torchaudio-2.2.1+cu121:\n",
      "      Successfully uninstalled torchaudio-2.2.1+cu121\n",
      "\u001b[31mERROR: pip's dependency resolver does not currently take into account all the packages that are installed. This behaviour is the source of the following dependency conflicts.\n",
      "torchtext 0.17.1 requires torch==2.2.1, but you have torch 2.0.0 which is incompatible.\n",
      "torchvision 0.17.1+cu121 requires torch==2.2.1, but you have torch 2.0.0 which is incompatible.\u001b[0m\u001b[31m\n",
      "\u001b[0mSuccessfully installed lit-18.1.6 nvidia-cublas-cu11-11.10.3.66 nvidia-cuda-cupti-cu11-11.7.101 nvidia-cuda-nvrtc-cu11-11.7.99 nvidia-cuda-runtime-cu11-11.7.99 nvidia-cudnn-cu11-8.5.0.96 nvidia-cufft-cu11-10.9.0.58 nvidia-curand-cu11-10.2.10.91 nvidia-cusolver-cu11-11.4.0.1 nvidia-cusparse-cu11-11.7.4.91 nvidia-nccl-cu11-2.14.3 nvidia-nvtx-cu11-11.7.91 torch-2.0.0 torchaudio-2.0.0 triton-2.0.0\n",
      "Looking in links: https://download.pytorch.org/whl/torch_stable.html\n",
      "Collecting torch==2.0.0+cu117\n",
      "  Downloading https://download.pytorch.org/whl/cu117/torch-2.0.0%2Bcu117-cp310-cp310-linux_x86_64.whl (1843.9 MB)\n",
      "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m1.8/1.8 GB\u001b[0m \u001b[31m1.1 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
      "\u001b[?25hCollecting torchvision==0.15.0+cu117\n",
      "  Downloading https://download.pytorch.org/whl/cu117/torchvision-0.15.0%2Bcu117-cp310-cp310-linux_x86_64.whl (6.1 MB)\n",
      "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m6.1/6.1 MB\u001b[0m \u001b[31m47.9 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
      "\u001b[?25hRequirement already satisfied: filelock in /usr/local/lib/python3.10/dist-packages (from torch==2.0.0+cu117) (3.14.0)\n",
      "Requirement already satisfied: typing-extensions in /usr/local/lib/python3.10/dist-packages (from torch==2.0.0+cu117) (4.11.0)\n",
      "Requirement already satisfied: sympy in /usr/local/lib/python3.10/dist-packages (from torch==2.0.0+cu117) (1.12)\n",
      "Requirement already satisfied: networkx in /usr/local/lib/python3.10/dist-packages (from torch==2.0.0+cu117) (3.3)\n",
      "Requirement already satisfied: jinja2 in /usr/local/lib/python3.10/dist-packages (from torch==2.0.0+cu117) (3.1.4)\n",
      "Requirement already satisfied: triton==2.0.0 in /usr/local/lib/python3.10/dist-packages (from torch==2.0.0+cu117) (2.0.0)\n",
      "Requirement already satisfied: numpy in /usr/local/lib/python3.10/dist-packages (from torchvision==0.15.0+cu117) (1.25.2)\n",
      "Requirement already satisfied: requests in /usr/local/lib/python3.10/dist-packages (from torchvision==0.15.0+cu117) (2.31.0)\n",
      "Requirement already satisfied: pillow!=8.3.*,>=5.3.0 in /usr/local/lib/python3.10/dist-packages (from torchvision==0.15.0+cu117) (9.4.0)\n",
      "Requirement already satisfied: cmake in /usr/local/lib/python3.10/dist-packages (from triton==2.0.0->torch==2.0.0+cu117) (3.27.9)\n",
      "Requirement already satisfied: lit in /usr/local/lib/python3.10/dist-packages (from triton==2.0.0->torch==2.0.0+cu117) (18.1.6)\n",
      "Requirement already satisfied: MarkupSafe>=2.0 in /usr/local/lib/python3.10/dist-packages (from jinja2->torch==2.0.0+cu117) (2.1.5)\n",
      "Requirement already satisfied: charset-normalizer<4,>=2 in /usr/local/lib/python3.10/dist-packages (from requests->torchvision==0.15.0+cu117) (3.3.2)\n",
      "Requirement already satisfied: idna<4,>=2.5 in /usr/local/lib/python3.10/dist-packages (from requests->torchvision==0.15.0+cu117) (3.7)\n",
      "Requirement already satisfied: urllib3<3,>=1.21.1 in /usr/local/lib/python3.10/dist-packages (from requests->torchvision==0.15.0+cu117) (2.0.7)\n",
      "Requirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.10/dist-packages (from requests->torchvision==0.15.0+cu117) (2024.2.2)\n",
      "Requirement already satisfied: mpmath>=0.19 in /usr/local/lib/python3.10/dist-packages (from sympy->torch==2.0.0+cu117) (1.3.0)\n",
      "Installing collected packages: torch, torchvision\n",
      "  Attempting uninstall: torch\n",
      "    Found existing installation: torch 2.0.0\n",
      "    Uninstalling torch-2.0.0:\n",
      "      Successfully uninstalled torch-2.0.0\n",
      "  Attempting uninstall: torchvision\n",
      "    Found existing installation: torchvision 0.17.1+cu121\n",
      "    Uninstalling torchvision-0.17.1+cu121:\n",
      "      Successfully uninstalled torchvision-0.17.1+cu121\n",
      "\u001b[31mERROR: pip's dependency resolver does not currently take into account all the packages that are installed. This behaviour is the source of the following dependency conflicts.\n",
      "torchtext 0.17.1 requires torch==2.2.1, but you have torch 2.0.0+cu117 which is incompatible.\u001b[0m\u001b[31m\n",
      "\u001b[0mSuccessfully installed torch-2.0.0+cu117 torchvision-0.15.0+cu117\n",
      "Get:1 https://cloud.r-project.org/bin/linux/ubuntu jammy-cran40/ InRelease [3,626 B]\n",
      "Hit:2 https://developer.download.nvidia.com/compute/cuda/repos/ubuntu2204/x86_64  InRelease\n",
      "Get:3 http://security.ubuntu.com/ubuntu jammy-security InRelease [110 kB]\n",
      "Hit:4 http://archive.ubuntu.com/ubuntu jammy InRelease\n",
      "Get:5 http://archive.ubuntu.com/ubuntu jammy-updates InRelease [119 kB]\n",
      "Hit:6 https://ppa.launchpadcontent.net/c2d4u.team/c2d4u4.0+/ubuntu jammy InRelease\n",
      "Hit:7 https://ppa.launchpadcontent.net/deadsnakes/ppa/ubuntu jammy InRelease\n",
      "Hit:8 https://ppa.launchpadcontent.net/graphics-drivers/ppa/ubuntu jammy InRelease\n",
      "Hit:9 http://archive.ubuntu.com/ubuntu jammy-backports InRelease\n",
      "Hit:10 https://ppa.launchpadcontent.net/ubuntugis/ppa/ubuntu jammy InRelease\n",
      "Get:11 http://archive.ubuntu.com/ubuntu jammy-updates/restricted amd64 Packages [2,462 kB]\n",
      "Get:12 http://security.ubuntu.com/ubuntu jammy-security/main amd64 Packages [1,850 kB]\n",
      "Get:13 http://archive.ubuntu.com/ubuntu jammy-updates/main amd64 Packages [2,122 kB]\n",
      "Get:14 http://security.ubuntu.com/ubuntu jammy-security/restricted amd64 Packages [2,389 kB]\n",
      "Fetched 9,057 kB in 6s (1,529 kB/s)\n",
      "Reading package lists... Done\n",
      "Reading package lists... Done\n",
      "Building dependency tree... Done\n",
      "Reading state information... Done\n",
      "ffmpeg is already the newest version (7:4.4.2-0ubuntu0.22.04.1).\n",
      "0 upgraded, 0 newly installed, 0 to remove and 45 not upgraded.\n"
     ]
    }
   ],
   "source": [
    "!pip install numpy scipy pillow opencv-python-headless scikit-image\n",
    "!pip install gdown paramiko\n",
    "!pip install kornia\n",
    "!pip install yacs\n",
    "!pip install gfpgan\n",
    "!pip install pydub\n",
    "!pip install facexlib\n",
    "!pip install torchaudio==2.0.0\n",
    "!pip install torch==2.0.0+cu117 torchvision==0.15.0+cu117 -f https://download.pytorch.org/whl/torch_stable.html\n",
    "!apt-get update\n",
    "!apt-get install ffmpeg"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 100,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "aHqqeSzCgE4Z",
    "outputId": "3a21130c-e1ba-4e94-a296-f325dc9c21ad"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Drive already mounted at /content/drive; to attempt to forcibly remount, call drive.mount(\"/content/drive\", force_remount=True).\n"
     ]
    }
   ],
   "source": [
    "from google.colab import drive\n",
    "drive.mount('/content/drive')\n",
    "\n",
    "import os\n",
    "base_dir = '/content/drive/MyDrive/SadTalker'\n",
    "checkpoints_dir = os.path.join(base_dir, 'checkpoints')\n",
    "weights_dir = os.path.join(base_dir, 'weights')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 101,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "cqrT4z_4foqm",
    "outputId": "0d7727f6-ac97-4ffd-9895-8d1d67679044"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Downloading...\n",
      "From: https://github.com/OpenTalker/SadTalker/releases/download/v0.0.2-rc/mapping_00109-model.pth.tar\n",
      "To: /content/drive/MyDrive/SadTalker/checkpoints/mapping_00109-model.pth.tar\n",
      "100% 156M/156M [00:00<00:00, 307MB/s]\n",
      "Downloading...\n",
      "From: https://github.com/OpenTalker/SadTalker/releases/download/v0.0.2-rc/mapping_00229-model.pth.tar\n",
      "To: /content/drive/MyDrive/SadTalker/checkpoints/mapping_00229-model.pth.tar\n",
      "100% 156M/156M [00:00<00:00, 297MB/s]\n",
      "Downloading...\n",
      "From: https://github.com/OpenTalker/SadTalker/releases/download/v0.0.2-rc/SadTalker_V0.0.2_256.safetensors\n",
      "To: /content/drive/MyDrive/SadTalker/checkpoints/SadTalker_V0.0.2_256.safetensors\n",
      "100% 725M/725M [00:02<00:00, 259MB/s]\n",
      "Downloading...\n",
      "From: https://github.com/OpenTalker/SadTalker/releases/download/v0.0.2-rc/SadTalker_V0.0.2_512.safetensors\n",
      "To: /content/drive/MyDrive/SadTalker/checkpoints/SadTalker_V0.0.2_512.safetensors\n",
      "100% 725M/725M [00:04<00:00, 148MB/s]\n",
      "Error:\n",
      "\n",
      "\t[Errno 2] No such file or directory:\n",
      "\t'/content/drive/MyDrive/SadTalker/weights'\n",
      "\n",
      "To report issues, please visit https://github.com/wkentaro/gdown/issues.\n",
      "Error:\n",
      "\n",
      "\t[Errno 2] No such file or directory:\n",
      "\t'/content/drive/MyDrive/SadTalker/weights'\n",
      "\n",
      "To report issues, please visit https://github.com/wkentaro/gdown/issues.\n",
      "Error:\n",
      "\n",
      "\t[Errno 2] No such file or directory:\n",
      "\t'/content/drive/MyDrive/SadTalker/weights'\n",
      "\n",
      "To report issues, please visit https://github.com/wkentaro/gdown/issues.\n",
      "Error:\n",
      "\n",
      "\t[Errno 2] No such file or directory:\n",
      "\t'/content/drive/MyDrive/SadTalker/weights'\n",
      "\n",
      "To report issues, please visit https://github.com/wkentaro/gdown/issues.\n",
      "Downloading...\n",
      "From: https://github.com/Winfredy/SadTalker/releases/download/v0.0.2/epoch_20.pth\n",
      "To: /content/drive/MyDrive/SadTalker/checkpoints/epoch_20.pth\n",
      "100% 289M/289M [00:01<00:00, 281MB/s]\n",
      "Error:\n",
      "\n",
      "\t[Errno 2] No such file or directory:\n",
      "\t'/content/drive/MyDrive/SadTalker/weights'\n",
      "\n",
      "To report issues, please visit https://github.com/wkentaro/gdown/issues.\n",
      "Error:\n",
      "\n",
      "\t[Errno 2] No such file or directory:\n",
      "\t'/content/drive/MyDrive/SadTalker/weights'\n",
      "\n",
      "To report issues, please visit https://github.com/wkentaro/gdown/issues.\n",
      "Error:\n",
      "\n",
      "\t[Errno 2] No such file or directory:\n",
      "\t'/content/drive/MyDrive/SadTalker/weights'\n",
      "\n",
      "To report issues, please visit https://github.com/wkentaro/gdown/issues.\n",
      "Error:\n",
      "\n",
      "\t[Errno 2] No such file or directory:\n",
      "\t'/content/drive/MyDrive/SadTalker/weights'\n",
      "\n",
      "To report issues, please visit https://github.com/wkentaro/gdown/issues.\n"
     ]
    }
   ],
   "source": [
    "# Downloading the checkpoints to Google Drive\n",
    "!gdown https://github.com/OpenTalker/SadTalker/releases/download/v0.0.2-rc/mapping_00109-model.pth.tar -O {checkpoints_dir}/mapping_00109-model.pth.tar\n",
    "!gdown https://github.com/OpenTalker/SadTalker/releases/download/v0.0.2-rc/mapping_00229-model.pth.tar -O {checkpoints_dir}/mapping_00229-model.pth.tar\n",
    "!gdown https://github.com/OpenTalker/SadTalker/releases/download/v0.0.2-rc/SadTalker_V0.0.2_256.safetensors -O {checkpoints_dir}/SadTalker_V0.0.2_256.safetensors\n",
    "!gdown https://github.com/OpenTalker/SadTalker/releases/download/v0.0.2-rc/SadTalker_V0.0.2_512.safetensors -O {checkpoints_dir}/SadTalker_V0.0.2_512.safetensors\n",
    "\n",
    "# Downloading facexlib and GFPGAN weights to Google Drive\n",
    "!gdown https://github.com/xinntao/facexlib/releases/download/v0.1.0/alignment_WFLW_4HG.pth -O {weights_dir}/alignment_WFLW_4HG.pth\n",
    "!gdown https://github.com/xinntao/facexlib/releases/download/v0.1.0/detection_Resnet50_Final.pth -O {weights_dir}/detection_Resnet50_Final.pth\n",
    "!gdown https://github.com/TencentARC/GFPGAN/releases/download/v1.3.0/GFPGANv1.4.pth -O {weights_dir}/GFPGANv1.4.pth\n",
    "!gdown https://github.com/xinntao/facexlib/releases/download/v0.2.2/parsing_parsenet.pth -O {weights_dir}/parsing_parsenet.pth\n",
    "!gdown https://github.com/Winfredy/SadTalker/releases/download/v0.0.2/epoch_20.pth -O {checkpoints_dir}/epoch_20.pth\n",
    "\n",
    "# Download the checkpoints to Google Drive if they don't already exist\n",
    "def download_if_not_exists(url, dest):\n",
    "    if not os.path.exists(dest):\n",
    "        !gdown {url} -O {dest}\n",
    "\n",
    "download_if_not_exists('https://github.com/OpenTalker/SadTalker/releases/download/v0.0.2-rc/mapping_00109-model.pth.tar', f'{checkpoints_dir}/mapping_00109-model.pth.tar')\n",
    "download_if_not_exists('https://github.com/OpenTalker/SadTalker/releases/download/v0.0.2-rc/mapping_00229-model.pth.tar', f'{checkpoints_dir}/mapping_00229-model.pth.tar')\n",
    "download_if_not_exists('https://github.com/OpenTalker/SadTalker/releases/download/v0.0.2-rc/SadTalker_V0.0.2_256.safetensors', f'{checkpoints_dir}/SadTalker_V0.0.2_256.safetensors')\n",
    "download_if_not_exists('https://github.com/OpenTalker/SadTalker/releases/download/v0.0.2-rc/SadTalker_V0.0.2_512.safetensors', f'{checkpoints_dir}/SadTalker_V0.0.2_512.safetensors')\n",
    "\n",
    "download_if_not_exists('https://github.com/xinntao/facexlib/releases/download/v0.1.0/alignment_WFLW_4HG.pth', f'{weights_dir}/alignment_WFLW_4HG.pth')\n",
    "download_if_not_exists('https://github.com/xinntao/facexlib/releases/download/v0.1.0/detection_Resnet50_Final.pth', f'{weights_dir}/detection_Resnet50_Final.pth')\n",
    "download_if_not_exists('https://github.com/TencentARC/GFPGAN/releases/download/v1.3.0/GFPGANv1.4.pth', f'{weights_dir}/GFPGANv1.4.pth')\n",
    "download_if_not_exists('https://github.com/xinntao/facexlib/releases/download/v0.2.2/parsing_parsenet.pth', f'{weights_dir}/parsing_parsenet.pth')\n",
    "download_if_not_exists('https://github.com/Winfredy/SadTalker/releases/download/v0.0.2/epoch_20.pth', f'{checkpoints_dir}/epoch_20.pth')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 108,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "M1ZTMIsLiLVH",
    "outputId": "4623b5aa-4d9a-4546-9e60-58d557b424ca"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Collecting edge-tts\n",
      "  Downloading edge_tts-6.1.11-py3-none-any.whl (28 kB)\n",
      "Requirement already satisfied: aiohttp>=3.8.0 in /usr/local/lib/python3.10/dist-packages (from edge-tts) (3.9.5)\n",
      "Requirement already satisfied: certifi>=2023.11.17 in /usr/local/lib/python3.10/dist-packages (from edge-tts) (2024.2.2)\n",
      "Requirement already satisfied: aiosignal>=1.1.2 in /usr/local/lib/python3.10/dist-packages (from aiohttp>=3.8.0->edge-tts) (1.3.1)\n",
      "Requirement already satisfied: attrs>=17.3.0 in /usr/local/lib/python3.10/dist-packages (from aiohttp>=3.8.0->edge-tts) (23.2.0)\n",
      "Requirement already satisfied: frozenlist>=1.1.1 in /usr/local/lib/python3.10/dist-packages (from aiohttp>=3.8.0->edge-tts) (1.4.1)\n",
      "Requirement already satisfied: multidict<7.0,>=4.5 in /usr/local/lib/python3.10/dist-packages (from aiohttp>=3.8.0->edge-tts) (6.0.5)\n",
      "Requirement already satisfied: yarl<2.0,>=1.0 in /usr/local/lib/python3.10/dist-packages (from aiohttp>=3.8.0->edge-tts) (1.9.4)\n",
      "Requirement already satisfied: async-timeout<5.0,>=4.0 in /usr/local/lib/python3.10/dist-packages (from aiohttp>=3.8.0->edge-tts) (4.0.3)\n",
      "Requirement already satisfied: idna>=2.0 in /usr/local/lib/python3.10/dist-packages (from yarl<2.0,>=1.0->aiohttp>=3.8.0->edge-tts) (3.7)\n",
      "Installing collected packages: edge-tts\n",
      "Successfully installed edge-tts-6.1.11\n"
     ]
    }
   ],
   "source": [
    "!pip install edge-tts"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "ajc8mgCfgdgd",
    "tags": []
   },
   "source": [
    "# Text to Audio model TTS"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 113,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "14RsyUy9iQPK",
    "outputId": "6bbbb154-86ac-4b05-db71-01bf9e8fb117"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Audio file saved as /content/drive/MyDrive/SadTalker/examples/driven_audio/generated_audio.wav\n"
     ]
    }
   ],
   "source": [
    "import edge_tts\n",
    "import asyncio\n",
    "import nest_asyncio\n",
    "\n",
    "# Allow nested event loops\n",
    "nest_asyncio.apply()\n",
    "\n",
    "# Convert text to audio\n",
    "def text_to_audio(text, filename):\n",
    "    async def _convert():\n",
    "        communicator = edge_tts.Communicate(text, voice=\"en-US-GuyNeural\")\n",
    "        await communicator.save(filename)\n",
    "\n",
    "    loop = asyncio.get_event_loop()\n",
    "    loop.run_until_complete(_convert())\n",
    "\n",
    "audio_filename = \"/content/drive/MyDrive/SadTalker/examples/driven_audio/generated_audio.wav\"\n",
    "text_to_audio(value[\"generation\"], audio_filename)\n",
    "print(f\"Audio file saved as {audio_filename}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "I6yXgVWcglRy"
   },
   "source": [
    "#Avatar video generation using SadTalker"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 117,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "KJ4pJ7ocgogs",
    "outputId": "0b739503-6b88-45d1-c64d-4dc6ddac8800"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "using safetensor as default\n",
      "3DMM Extraction for source image\n",
      "landmark Det:: 100% 1/1 [00:00<00:00,  8.84it/s]\n",
      "3DMM Extraction In Video:: 100% 1/1 [00:00<00:00, 17.03it/s]\n",
      "mel:: 100% 4977/4977 [00:00<00:00, 42245.13it/s]\n",
      "audio2exp:: 100% 498/498 [00:01<00:00, 452.98it/s]\n",
      "Face Renderer:: 100% 4977/4977 [02:39<00:00, 31.23it/s]\n",
      "The generated video is named /content/drive/MyDrive/SadTalker/results/2024_05_21_11.32.39/obama##generated_audio.mp4\n",
      "OpenCV: FFMPEG: tag 0x5634504d/'MP4V' is not supported with codec id 12 and format 'mp4 / MP4 (MPEG-4 Part 14)'\n",
      "OpenCV: FFMPEG: fallback to use tag 0x7634706d/'mp4v'\n",
      "seamlessClone:: 100% 4977/4977 [04:45<00:00, 17.43it/s]\n",
      "The generated video is named /content/drive/MyDrive/SadTalker/results/2024_05_21_11.32.39/obama##generated_audio_full.mp4\n",
      "face enhancer....\n",
      "Face Enhancer:: 100% 4977/4977 [13:44<00:00,  6.04it/s]\n",
      "IMAGEIO FFMPEG_WRITER WARNING: input image is not divisible by macro_block_size=16, resizing from (656, 716) to (656, 720) to ensure video compatibility with most codecs and players. To prevent resizing, make your input image divisible by the macro_block_size or set the macro_block_size to 1 (risking incompatibility).\n",
      "The generated video is named /content/drive/MyDrive/SadTalker/results/2024_05_21_11.32.39/obama##generated_audio_enhanced.mp4\n",
      "The generated video is named: /content/drive/MyDrive/SadTalker/results/2024_05_21_11.32.39.mp4\n",
      "Generated Video: /content/drive/MyDrive/SadTalker/results/2024_05_21_11.32.39.mp4\n"
     ]
    }
   ],
   "source": [
    "# SadTalker inference prep\n",
    "source_image_path = \"/content/drive/MyDrive/SadTalker/examples/source_image/obama.png\"\n",
    "result_dir = \"/content/drive/MyDrive/SadTalker/results\"\n",
    "checkpoint_dir = \"/content/drive/MyDrive/SadTalker/checkpoints\"\n",
    "audio_filename = \"/content/drive/MyDrive/SadTalker/examples/driven_audio/generated_audio.wav\"\n",
    "\n",
    "# directories checking\n",
    "os.makedirs(result_dir, exist_ok=True)\n",
    "os.makedirs(checkpoint_dir, exist_ok=True)\n",
    "\n",
    "#SadTalker inference\n",
    "!python /content/drive/MyDrive/SadTalker/inference.py --driven_audio {audio_filename} --source_image {source_image_path} --result_dir {result_dir} --still --preprocess full --enhancer gfpgan --checkpoint_dir {checkpoint_dir} --batch_size 1\n",
    "\n",
    "# ensuring we are getting the latest generated video\n",
    "def get_latest_generated_video(result_dir):\n",
    "    video_files = [os.path.join(result_dir, file) for file in os.listdir(result_dir) if file.endswith(\".mp4\")]\n",
    "    if not video_files:\n",
    "        return None\n",
    "    latest_video = max(video_files, key=os.path.getmtime)\n",
    "    return latest_video\n",
    "\n",
    "generated_video = get_latest_generated_video(result_dir)\n",
    "print(f\"Generated Video: {generated_video}\")\n",
    "\n",
    "# Displaying the video in the notebook\n",
    "if generated_video:\n",
    "    from IPython.display import display, Video\n",
    "    display(Video(generated_video, embed=True, width=600, height=400))\n",
    "else:\n",
    "    print(\"No video file generated.\")"
   ]
  }
 ],
 "metadata": {
  "accelerator": "GPU",
  "colab": {
   "collapsed_sections": [
    "PP6bqJx7HJ9-",
    "GY7xuOGYHJ9_",
    "EDpl6fm3HJ9_",
    "-VIDnsOTHJ-A",
    "fR3qZzdnHJ-B"
   ],
   "gpuType": "A100",
   "machine_shape": "hm",
   "provenance": []
  },
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.5"
  },
  "vscode": {
   "interpreter": {
    "hash": "5e840657db051c1a92f83b3e42bcf6859f1d8235e91eec9f2ab6f2488ac32497"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
